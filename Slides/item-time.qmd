---
title: "Item Response Theory for beginners"
subtitle: "Item time!"
author: "Dr. Ottavia M. Epifania"
institute: "Rovereto (TN)"
date: "University of Trento, \\ 17 November 2023"
format: 
  revealjs: 
    theme: serif
    incremental: true  
    slide-number: true
    show-slide-number: all
    embed-resources: true
    menu: 
      side: left
      width: normal
editor: source
fontsize: 20pt
execute: 
  eval: true
  echo: false
  warning: false
  fig-align: center
  out-width: 80%
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, 
                      warning = F, 
                      message = F, 
                      fig.align = "center", 
                      out.width = "90%", 
                      class.output="scroll-100")
hook_output <- knitr::knit_hooks$get("output")
knitr::knit_hooks$set(purl = knitr::hook_purl)

knitr::knit_hooks$set(output = function(x, options) {
  if (!is.null(n <- options$out.lines)) {
    x <- xfun::split_lines(x)
    if (length(x) > n) {
      # truncate the output
      x <- c(head(x, n), "....\n")
    }
    x <- paste(x, collapse = "\n")
  }
  hook_output(x, options)
})
library(TAM)
library(mokken)
library(lavaan)
library(difR)
library(sirt)
library(ggplot2)
library(tidyverse)
library(knitr)
set.seed(999)
N = 1000
b <- runif(5, -3,3)
a = c(runif(5, 0.4, 2))
true_theta = seq(-4, 4, length.out = N)
data <- sirt::sim.raschtype( true_theta, b=b, 
                             fixed.a = a)
true_thetaES = seq(-5, 2, length.out = N-200)
bES <- runif(8, -5,5)
aES = rep(1, 8)

dataES = sirt::sim.raschtype(true_thetaES, b = bES, fixed.a=aES)


IRT <- function(theta, a = 1, b = 0, c = 0,e = 1) {
  y <- c + (e - c) * exp(a * (theta - b)) / (1 + exp(a * (theta - b)))
  y[is.na(y)] = 1
  return(y)
}

i_info <- function(b, a=1,c=0, theta = seq(-5,5,length.out=1000)){
 
P <- NULL 
Q <- NULL
Ii <- NULL
for(i in 1:1000){
  P[i] <- 1/(1+ exp (-a*(theta[i] - b)))
  Q[i]= 1-P[i]
  Ii[i] =(a*Q[i]*(P[i]-c)^2)/(P[i]*((1-c)^2)) # (3PL)
   }
return(Ii)
}
# Function to get all item information
item_info <- function(b,a=1, c= 0){
item <- NULL
  for(i in 1:length(b)){
  item[[i]] <- i_info(b[i],a[i])
  }
return(item)
}

set.seed(999)

theta = seq(-4,4,length.out=1000)
library(xtable)


```

# Item fit 

## 
<br>

The fit of each item to the model can be evaluated: 

- $S - X^2$ (Orland & Thissen, 2000): Statistics based on the $\chi^2$. If significant, the item does not fit to the model (not suggested)

<br>

- *Root Mean Squared Deviation* (RMSD): Difference between what expected under the model and reala data (the lower the better). Values under $.15$ define an acceptable fit of the item to the model, values under $.10$ are optimal 

<br>

- Rasch model only $\rightarrow$ Infit and outfit statistics

## Evaluating item fit I {.scrollable}

:::{.panel-tabset}

## Look at the data 


```{r eval =T, echo = FALSE}
data = read.csv("data/itemClass.csv", header = T, sep = ",")
prop_item = data.frame(item = names(colMeans(data[, -c(1:2)])), 
           proportion = colMeans(data[, -c(1:2)]))

ggplot(prop_item, 
       aes(x = reorder(item, proportion), 
           y = proportion), color = item) + geom_bar(stat = "identity") + theme_light() + 
  ylab("Proportion correct") + ylim(0, 1) +
  theme(legend.position = "none", 
        axis.title = element_text(size = 26), 
        axis.title.x = element_blank(), 
        axis.text = element_text(size = 22))

```



<details><summary>Show code</summary>
```{r eval =FALSE, echo = TRUE}
data = read.csv("data/itemClass.csv", header = T, sep = ",")
prop_item = data.frame(item = names(colMeans(data[, -c(1:2)])), 
           proportion = colMeans(data[, -c(1:2)]))

ggplot(prop_item, 
       aes(x = reorder(item, proportion), 
           y = proportion), color = item) + geom_bar(stat = "identity") + theme_light() + 
  ylab("Proportion correct") + ylim(0, 1) +
  theme(legend.position = "none", 
        axis.title = element_text(size = 26), 
        axis.title.x = element_blank(), 
        axis.text = element_text(size = 22))
```
</details>

## Fitting & choosing a model {.scrollable}

```{r echo = FALSE}
m1pl = tam.mml(data[, grep("item", colnames(data))], verbose = F)
m2pl = tam.mml.2pl(data[, grep("item", colnames(data))], irtmodel = "2PL", verbose = F)
m3pl = tam.mml.3pl(data[, grep("item", colnames(data))], est.guess = grep("item", colnames(data)), verbose = F)
IRT.compareModels(m1pl, m2pl, m3pl) 
```


<details><summary>Show code</summary>
```{r eval =FALSE, echo = TRUE}
m1pl = tam.mml(data[, grep("item", colnames(data))], verbose = F)
m2pl = tam.mml.2pl(data[, grep("item", colnames(data))], irtmodel = "2PL", verbose = F)
m3pl = tam.mml.3pl(data[, grep("item", colnames(data))], est.guess = grep("item", colnames(data)), verbose = F)
IRT.compareModels(m1pl, m2pl, m3pl) 

```
</details>

## Fit of the model 


```{r echo = FALSE}
fit_m1pl = tam.modelfit(m1pl, progress = F)

fit_m1pl$statlist %>% kable(align = "c", 
                            row.names = FALSE, 
                            digits = rep(2, 4))
```


<details><summary>Show code</summary>
```{r eval =FALSE, echo = TRUE}
fit_m1pl$statlist
```
</details>



:::


## Evaluating item fit II {.scrollable}

:::{.panel-tabset}

## Item fit 

```{r out.lines = 20}
item_fit_1pl = IRT.itemfit(m1pl)
str(item_fit_1pl)
```


## $\chi^2$


```{r echo = FALSE}
item_fit_1pl$chisquare_stat


```


<details><summary>Show code</summary>
```{r eval =FALSE, echo = TRUE}
item_fit_1pl$chisquare_stat
```
</details>

## RMSD


```{r echo = FALSE}
item_fit_1pl$RMSD_summary %>% kable(aling = "c", digits = 2)
item_fit_1pl$RMSD %>% kable(aling = "c", digits = 2)
```


<details><summary>Show code</summary>
```{r eval =FALSE, echo = TRUE}
item_fit_1pl$RMSD_summary %>% kable(aling = "c", digits = 2)
item_fit_1pl$RMSD %>% kable(aling = "c", digits = 2)
```
</details>

:::


# Differential Item Functioning 


## An example 

<br>

<br>

The mass of Iodine 131 decreases by 1/2 every 8 days because of radioactive decay. 

In a laboratory, there are 2grams of Iodine 131. How many grams there would be after 16 days? 

<br>

<br>

<br>


<details><summary>Correct response</summary>
0.5grams
</details>

## 


```{r}
#| echo: false
b = c(-0.5616, -0.07)
a = c(1,1)


par(mar = c(5,7,4,2) + 0.1) 
plot(theta, IRT(theta, b = b[1], a = a[1]),
     cex.lab= 2.5, 
     cex.axis =1.5, cex.main = 3,
       xlab = expression(theta), ylab = "P(x = 1)",
       xlim = c(-4, 4), ylim = c(0, 1), 
     type = "l", lwd = 3, 
     col = "royalblue", main = "Item Charcteristic Curve (ICC)")
text(x= -1.5, y = 0.6, "M", col = "royalblue", cex = 2)
lines(theta, IRT(theta, b=b[2], 
                a = 1), 
      lty = 1, lwd=3, col = "magenta")
text(x= 1.5, y = 0.6, "F", col = "magenta", cex = 2)
```


## 


<br>

<br>

The same item presented to two different groups paired for their level of latent trait... does not have the same probability of being endorsed!

<br>
The subjects are paired according to their level of the latent trait. **Are there any differences in the performance to the item**?

<br>
Theoretically: Different subjects but with the same level of the latent trait (i.e., **paired**) should have similar performances on the item


<br>
If this expectation is not met $\rightarrow$ **Differential Item Functioning** (**DIF**)


## Reference vs. focal group

<br>

<br>

The comparison to investigate items with DIF is between two groups: 

<br>

- **Reference group**: It is the "baseline" group. For instance, if the test/questionnaire has been validated in a second language, the reference group is the original group

<br>

- **Focal group**: It is the focus of the DIF investigation, where we suepct the items of the test might be working differently 

## Uniform DIF 

The item "favors" one of the two groups (either the focal or the reference one) *constantly*

```{r}
#| echo: false
difficulty <- c(-1, 1)
par(mar = c(5,7,4,2) + 0.1) 
 theta <- theta <- seq(-7, 7, .001)
plot(theta, IRT(theta, b=difficulty[1]),
     cex.lab= 2, 
     cex.axis =1.5,
       xlab = expression(theta), ylab = expression(paste("P(", x[vi], " = 1)")),
       xlim = c(-5, 5), ylim = c(0, 1), 
     type = "l", lwd = 3, 
     col = "royalblue")

#item B
lines(theta, IRT(theta, b = difficulty[2]), 
      lty = 4, lwd=3, col = "magenta")
```

## Not-uniform DIF 

The item favors one of the group $\rightarrow$ it is not constant along the latent trait

```{r}
#| echo: false
difficulty <- c(1, 1)
par(mar = c(5,7,4,2) + 0.1) 
 theta <- theta <- seq(-7, 7, .001)
plot(theta, IRT(theta, b=difficulty[1], a = 1),
     cex.lab= 2, 
     cex.axis =1.5,
       xlab = expression(theta), ylab = expression(paste("P(", x[vi], " = 1)")),
       xlim = c(-5, 5), ylim = c(0, 1), 
     type = "l", lwd = 3, 
     col = "royalblue")

#item B
lines(theta, IRT(theta, b = difficulty[2], a = 1.5), 
      lty = 4, lwd=3, col = "magenta")
```


## DIF Investigation

IRT-based methods: Subjects are paired according to the estimates of their *latent trait level* $\theta$

Score-based methods: Subjects are paired to the the *observed score*



:::: {.columns}

::: {.column}

<div style="text-align: center;">
Uniform DIF 
</div>

- 1PL

- 2PL 

- 3PL 



:::

::: {.column}

<div style="text-align: center;">
Non-uniform DIF 
</div>

- 2PL 

- 3PL

:::

::::

## Likelihood Ratio Test 

Thissen, Steinber, & Wainer (1998)

Two IRT models: 

1. A "no DIF" model $\rightarrow$ parameters are constrained to be equal in the two groups 

2. A "DIF" model $\rightarrow$ parameters are left free to vary between the two groups 

. . .

It is like the LRT on a linear model where the group belonging (Focal Vs. Reference) is used as a predictor or not


## Lord 

Lord (1980)

The item parameters are estimated in both the reference and the focal groups

If there is a significant difference in the item estimates between groups $\rigtharrow$ DIF 

Beyond significance: Lord's $\Delta$:

- $< 1.00$: Negligible DIF 

- $1.00 < d < 1.5$: Moderate DIF 

- $> 1.5$: High DIF 

## Raju's Area  

Raju (1988)

<br>

It considers the DIF as the area between the ICCs of the items

<br>

If the area between the ICCs is 0, then the item presents no DIF


## A note on Lord and Raju 

The parameters estimated in the focal and reference groups cannot be directly compared $\rightarrow$ the parameters in one of the groups **must** be rescaled.

. . .

The rescaling can be done according to the *equal means anchoring* (Cook & Eignor, 1991)

. . .

This method is already applied by the `difR` package 

## Equal means anchoring

First, a constant must be computed: 

$$c = \bar{b}_R - \bar{b}_F$$

Then, it is substracted from the estimates of the items in the **reference group**:

$$b' = b_Ri - c$$

## DIF -- Import data {.scrollable}

The dataset is the `difClass.csv` dataset 

<details><summary>Show data & code </summary>
```{r}
data = read.csv("data/difClass.csv", header = T, sep = ",")
head(data)
```
</details>


::: {.panel-tabset}

## Look at the data 
```{r eval = T, echo = FALSE}
long = pivot_longer(data, !1:2, names_to = "item", 
             values_to = "correct")
prop_gender = long %>% 
  group_by(item, gender) %>%  
  summarise(prop = mean(correct), sd = sd(correct))

ggplot(prop_gender, 
       aes( x = item, y= prop, fill = gender)) + 
  geom_bar(stat = "identity", position = position_dodge()) + ylim(0,1) + 
  theme_light() + ylab("Item probability") + 
  theme(legend.direction="horizontal", 
        legend.position = c(.5,.9), 
        legend.title = element_blank(), 
        axis.text = element_text(size = 10), 
        axis.title = element_text(size = 12), 
        axis.title.x = element_blank(), 
        legend.text = element_text(size = 12)) + 
  geom_hline(yintercept = .25, linetype = 2) +
  geom_hline(yintercept = .5, linetype = 2) +
  geom_hline(yintercept = .75, linetype = 2)

```

<details><summary>Show code</summary>
```{r eval = F, echo = TRUE}
long = pivot_longer(data, !1:2, names_to = "item", 
             values_to = "correct")
prop_gender = long %>% 
  group_by(item, gender) %>%  
  summarise(prop = mean(correct), sd = sd(correct))

ggplot(prop_gender, 
       aes( x = item, y= prop, fill = gender)) + geom_bar(stat = "identity", position = position_dodge()) + ylim(0,1)

```
</details>

## Fit & Choose a model 


```{r}
m1pl = tam.mml(data[, grep("item", colnames(data))], verbose = F)
m2pl = tam.mml.2pl(data[, grep("item", colnames(data))], irtmodel = "2PL", verbose = F)
m3pl = tam.mml.3pl(data[, grep("item", colnames(data))], est.guess = grep("item", colnames(data)),
                     verbose = F)
IRT.compareModels(m1pl, m2pl, m3pl)
```


## Model fit 

```{r}
fit_m1pl = tam.modelfit(m1pl, progress = F)
fit_m1pl$statlist

```


## Item fit 

```{r}
item_fit_1pl = IRT.itemfit(m1pl)
item_fit_1pl$RMSD_summary
 fit_m1pl$Q3_summary
```


::: 

## DIF -- LRT {.scrollable}

This is not properly the LRT but an approximation. 

```{r eval = FALSE }
#| code-line-numbers: "|1|2-3|4|5|6-7"
est_theta = IRT.factor.scores(m1pl)$EAP
lrt_dif = difGenLogistic(data[, !colnames(data) %in% c("id", "gender")],
                           group = as.factor(data$gender), focal.names = "f",
                           type = "udif",
                           alpha = .001, p.adjust.method = "BH",
                           match = est_theta,
                           criterion = "LRT")
```


. . .

```{r echo = FALSE}
est_theta = IRT.factor.scores(m1pl)$EAP
lrt_dif = difGenLogistic(data[, !colnames(data) %in% c("id", "gender")],
                           group = as.factor(data$gender), focal.names = "f",
                           type = "udif",
                           alpha = .001, p.adjust.method = "BH",
                           match = est_theta,
                           criterion = "LRT")
lrt_dif
```



## DIF -- Raju 

```{r}
rajDif = difRaju(data[, !colnames(data) %in% c("id")], 
                  group = "gender",  focal.name = "f", 
                  model = "1PL", 
                  alpha = .001, p.adjust.method = "BH")
rajDif

```


## DIF -- Lord 

```{r}
lordDif = difLord(data[, !colnames(data) %in% "id"], 
                  group = "gender",  focal.name = "f", 
                  model = "1PL", 
                   alpha = .001, p.adjust.method = "BH")
```

## Details Raju and Lord 

`mF-mR`: Difference between the focal and reference group (the estimates in the reference group are already rescaled)

`deltaLord`: effect-size, it is obtained by multiplying `mF-mR` $\times -2.35$ (Penfield & Camilli, 2007)

The size of the effect can be interpreted according to the values reported in the `R` output 

The item parameters can be obtained as: 

```{r eval = FALSE}
lordDif$itemParInit
```

## Caution advised!

The object obtained from `lordDif$itemParInit` has a number of rows equal 2 times the number of items: 

- rows $i, 1\ldots, I$: Estimates of the items in the **REFERENCE GROUP**

- rows $i+1, \ldots 2I$: Estimates of the items in the **FOCAL GROUP**

::: {.panel-tabset}

## Item estimates: Reference group 

Rows $i, 1\ldots, I$. These estimates **are not** rescaled

```{r}
item_par = lordDif$itemParInit
item_par[1:10, ]
```


## Item estimates: Focus group 

Rows $i+1, \ldots 2I$

```{r}
item_par[11:nrow(item_par), ]
```


::: 

## Rescaling -- Practice
```{r eval = FALSE}
#| code-line-numbers: "|1-2|3|4|5|6"
itemFR = data.frame(cbind(item_par[11:nrow(item_par), ], item_par[1:10, ]))
colnames(itemFR)[c(1,3)] = paste0(rep("b",2),  c("F", "R"))
itemFR$constant = mean(itemFR$bR) - mean(itemFR$bF)
itemFR$new_bR = itemFR$bR - itemFR$constant
itemFR$DIF_correct = itemFR$bF- itemFR$new_bR
itemFR
```

. . .

```{r eval = TRUE, echo = FALSE}
#| code-line-numbers: "|1-2|3|4|5|6"
itemFR = data.frame(cbind(item_par[11:nrow(item_par), ], item_par[1:10, ]))
colnames(itemFR)[c(1,3)] = paste0(rep("b",2),  c("F", "R"))
itemFR$constant = mean(itemFR$bR) - mean(itemFR$bF)
itemFR$new_bR = itemFR$bR - itemFR$constant
itemFR$DIF_correct = itemFR$bF- itemFR$new_bR
itemFR
```

