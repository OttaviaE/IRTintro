<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Item Response Theory for beginners</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr. Ottavia M. Epifania" />
    <script src="libs/header-attrs-2.25/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Item Response Theory for beginners
]
.subtitle[
## Model estimation, model comparison, assumptions check in R
]
.author[
### Dr. Ottavia M. Epifania
]
.institute[
### Rovereto (TN)
]
.date[
### University of Trento,  17 November 2023
]

---





&lt;style type="text/css"&gt;
pre {
  max-height: 700px;
  overflow-y: auto;
}
pre[class] {
  max-height: 500px;
}
.scroll-100 {
  max-height: 500px;
  overflow-y: auto;
}

.inverse {
  background-color: #272822;
  color: #d6d6d6;
  text-shadow: 0 0 20px #333;
}


.scrollable {
  height: 500px;
  overflow-y: auto;
}


.scrollable-auto {
  height: 80%;
  overflow-y: auto;
}

.remark-slide-number {
  display: none;
}
&lt;/style&gt;


---
class: section, center, middle

# Getting started 

---

## Create a new project I 
(This is not mandatory by it is strongly suggested)

New file `\(\rightarrow\)` New project

&lt;img src="img/project1.png" width="90%" style="display: block; margin: auto;" /&gt;
---


## Create a new project II 

.pull-left[ 
&lt;img src="img/project2.png" width="90%" style="display: block; margin: auto;" /&gt;

]

.pull-right[
&lt;img src="img/project3.png" width="90%" style="display: block; margin: auto;" /&gt;

]



---


## Packages

.pull-left[
.center[Installation -- Run only once]

```r
install.packages("lavaan")

install.packages("TAM")

install.packages("mokken")

install.packages("difR")

install.packages("tidyverse")

install.packages("ggplot2")
```


]


.pull-right[
.center[Upload in `R` -- Everytime]


```r
library("lavaan")

library("TAM")

library("mokken")

library("difR")

library("tidyverse")

library("ggplot2")
```


]

---

## Useful code




```r
# probability of a correct response given theta and item parameters
IRT &lt;- function(theta, a = 1, b = 0, c = 0,e = 1) {
  y &lt;- c + (e - c) * exp(a * (theta - b)) / (1 + exp(a * (theta - b)))
  y[is.na(y)] = 1
  return(y)
}
```

---

## Useful code II


.scrollable[


```r
# function for plotting the ICCs of the items 
# returns a list with a ggplot graph (icc_graph) and a data set with the data 
# used for plotting the ICC (icc_data)
irt_icc = function(model) {
  item_par = model$item
  est_theta = seq(-4,4, length.out=1000)
  item_prob = list()
  if (any(grep("guess", colnames(item_par))) == F) {
    for (i in 1:nrow(item_par)) {
      item_prob[[i]] = data.frame(theta = est_theta)
      item_prob[[i]]$it_p = IRT(item_prob[[i]]$theta, 
                          b = item_par[i, "xsi.item"], 
                          a = item_par[i, "B.Cat1.Dim1"])
      item_prob[[i]]$item = item_par[i, "item"]

}
  } else {
     for (i in 1:nrow(item_par)) {
      item_prob[[i]] = data.frame(theta = est_theta)
      item_prob[[i]]$it_p = IRT(item_prob[[i]]$theta, 
                          b = item_par[i, "AXsi_.Cat1"], 
                          a = item_par[i, "B.Cat1.Dim1"], 
                          c = item_par[i, "guess"])
      item_prob[[i]]$item = item_par[i, "item"]

}
  }
  p = do.call("rbind", item_prob)
  gp = ggplot(p, 
       aes(x = theta, y = it_p, group = item, col =
             item)) + geom_line(lwd = 1)
  object = list(icc_data = p, 
              icc_graph = gp)

return(object)
}
```
]



---

## Useful code III

.scrollable[

```r
irt_iif = function(model) {
  est_theta = IRT.factor.scores(model, 
                              type = "EAP")$EAP
ii = IRT.informationCurves(model, theta = est_theta)

test_info = data.frame(theta = est_theta, 
               info = ii$test_info_curve, 
               se = ii$se_curve)

iif_info = list()
for(i in 1:nrow(ii$info_curves_item)) {
    iif_info[[i]] = data.frame(theta = est_theta)
    iif_info[[i]]$ii_item = ii$info_curves_item[i, ]
    iif_info[[i]]$item = dimnames(ii$info_curves_item)[[1]][i]
}

dat_info = do.call("rbind", iif_info)

info_tot = list(test_info = test_info, 
                item_info = dat_info)

return(info_tot)
}
```

]




---
class: section, center, middle

# Data import

---

## Import data in R


.scrollable[
Download the file  `dataClass.csv` from this shared folder [Dati](https://drive.google.com/drive/folders/1PXDG7HhjRDMdFEQjk5WQQWdiorDpSgtw?usp=sharing)

Store the downloaded file in the `Data` sub folder of your newly created project and run this code: 


```r
data = read.csv("Data/dataClass.csv", header = T, sep = ",")
```
]

---

## Look at the data - Item I

.scrollable[


```r
vis_data = data
vis_data$id = paste0("s", 1:nrow(data))

vis_data = vis_data[, c(ncol(vis_data), 1:ncol(data))]
vis_data = pivot_longer(vis_data, names_to = "item", cols = -1)

prop_data = vis_data %&gt;% 
  group_by(item) %&gt;%  
  summarise(proportion = mean(value))

ggplot(prop_data, 
       aes(x = reorder(item, proportion), y=proportion, 
           fill = item)) + geom_bar(stat = "identity") + 
  theme(axis.text = element_text(angle = 90)) + geom_hline(aes(yintercept=.50), linetype = 2) + 
  theme_light() + ylim(0, 1)
```

&lt;img src="stimareImodelli_files/figure-html/unnamed-chunk-12-1.png" width="90%" style="display: block; margin: auto;" /&gt;


]

---




## Look at the data - Respondents
.scrollable[

```r
sbj_data = data
sbj_data$id = paste0("s", 1:nrow(data))
sbj_data = sbj_data[, c(ncol(sbj_data), 1:ncol(data))]

sbj_data$sum = rowSums(sbj_data[,-1])

boxplot(sbj_data$sum)
```

&lt;img src="stimareImodelli_files/figure-html/unnamed-chunk-13-1.png" width="90%" style="display: block; margin: auto;" /&gt;
]

---

class: section, center, middle

# Assumptions

---


## IRT assumptions 

There are three main assumptions: 

1. Unidimensionality 

2. Monotonicity 

3. Local independence 

If these assumptions are violated, the models can still be fitted but their interpretation if meaningless

---

## Unidimensionality

.center[What]

Unidimensionality `\(\rightarrow\)` There's only one latent trait that is responsible of the observed responses 

.center[How]


**Confirmatory Factor Analysis models** (CFA)

--

.center[If violated]

The parameter estimates might be distorted and/or could not be interpreted

Even if the estimates could be interpreted, they would have no meaning because the model has no meaning 

-- 

.center[Execption]

There are IRT models that are designed for dealing with multidimensional latent traits

---


## Unidimensionality - CFA

CFA models that force a one-factor solution to the data: 

- If the one-factor model presents a good fit to the data `\(\rightarrow\)` it is reasonable to assume the unidimensionality

- If the one-factor model presents does not present a good fit to the data `\(\rightarrow\)` unidimensionality is not supporteed, it is best to first understand the latent structure of the data

--

.center[How]

CFA fit indexes: 

Comparative Fit Index (CFI) `\(&gt; .90\)`


Standardized Root Mean Square Residual (SRMSR) `\(&lt;.08\)`

Root Mean Square Error of Approximation (RMSEA) `\(&lt;. 08\)`

---

## Unidimensionality - Practice 

The CFA model is fitted with the `lavaan` package:

.scrollable[

```r
item_lab = paste(colnames(data), collapse = " + ")
form = paste("latent =~", item_lab)

form
```

```{.scroll-100}
## [1] "latent =~ I01 + I02 + I03 + I04 + I05"
```


```r
model = cfa(form, data = data,  ordered = colnames(data))
summary(model, fit.measures = T)
```

```{.scroll-100}
## lavaan 0.6.16 ended normally after 15 iterations
## 
##   Estimator                                       DWLS
##   Optimization method                           NLMINB
##   Number of model parameters                        10
## 
##   Number of observations                          1000
## 
## Model Test User Model:
##                                               Standard      Scaled
##   Test Statistic                                 1.643       3.095
##   Degrees of freedom                                 5           5
##   P-value (Chi-square)                           0.896       0.685
##   Scaling correction factor                                  0.551
##   Shift parameter                                            0.115
##     simple second-order correction                                
## 
## Model Test Baseline Model:
## 
##   Test statistic                              2945.814    2439.475
##   Degrees of freedom                                10          10
##   P-value                                        0.000       0.000
##   Scaling correction factor                                  1.208
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    1.000       1.000
##   Tucker-Lewis Index (TLI)                       1.002       1.002
##                                                                   
##   Robust Comparative Fit Index (CFI)                         1.000
##   Robust Tucker-Lewis Index (TLI)                            1.008
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.000       0.000
##   90 Percent confidence interval - lower         0.000       0.000
##   90 Percent confidence interval - upper         0.019       0.034
##   P-value H_0: RMSEA &lt;= 0.050                    0.999       0.995
##   P-value H_0: RMSEA &gt;= 0.080                    0.000       0.000
##                                                                   
##   Robust RMSEA                                               0.000
##   90 Percent confidence interval - lower                     0.000
##   90 Percent confidence interval - upper                     0.089
##   P-value H_0: Robust RMSEA &lt;= 0.050                         0.810
##   P-value H_0: Robust RMSEA &gt;= 0.080                         0.073
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.014       0.014
## 
## Parameter Estimates:
## 
##   Standard errors                           Robust.sem
##   Information                                 Expected
##   Information saturated (h1) model        Unstructured
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   latent =~                                           
##     I01               1.000                           
##     I02               1.516    0.096   15.845    0.000
##     I03               1.035    0.088   11.716    0.000
##     I04               1.180    0.083   14.202    0.000
##     I05               1.436    0.088   16.291    0.000
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .I01               0.000                           
##    .I02               0.000                           
##    .I03               0.000                           
##    .I04               0.000                           
##    .I05               0.000                           
##     latent            0.000                           
## 
## Thresholds:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##     I01|t1           -0.181    0.040   -4.549    0.000
##     I02|t1            0.146    0.040    3.665    0.000
##     I03|t1           -0.610    0.042  -14.364    0.000
##     I04|t1            0.637    0.043   14.915    0.000
##     I05|t1            0.539    0.042   12.885    0.000
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .I01               0.618                           
##    .I02               0.123                           
##    .I03               0.591                           
##    .I04               0.468                           
##    .I05               0.212                           
##     latent            0.382    0.044    8.740    0.000
## 
## Scales y*:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##     I01               1.000                           
##     I02               1.000                           
##     I03               1.000                           
##     I04               1.000                           
##     I05               1.000
```

]

---

## Monotonicity 

.center[What]

The probability of responding correctly increases as the the level of the latent trait increases

.center[How]

Monotonicitiy is evaluated at the item level with `\(H\)` coefficient by Mokken: 

   `\(H \leq .30\)` `\(\rightarrow\)` The item is not monotone, should be discarded
   
   `\(.30 &lt; H \leq .50\)` `\(\rightarrow\)` The item is essentially monotone, this is fine 
   
   `\(H &gt; .50\)` `\(\rightarrow\)` The item is monotone, this is otpimal
   

.center[If violated]

Issues on the reliability and validity of the measure 

   
---


## Monotonicity in R

Monotonicity is checked with the `mokken` package in `R`:


```r
library(mokken)
mono_check = check.monotonicity(data)
summary(mono_check)
```

```{.scroll-100}
##     ItemH #ac #vi #vi/#ac maxvi  sum sum/#ac zmax #zsig crit
## I01  0.47  10   0     0.0  0.00 0.00  0.0000 0.00     0    0
## I02  0.65  10   0     0.0  0.00 0.00  0.0000 0.00     0    0
## I03  0.55  10   1     0.1  0.05 0.05  0.0049 1.56     0   18
## I04  0.55  10   0     0.0  0.00 0.00  0.0000 0.00     0    0
## I05  0.63   6   0     0.0  0.00 0.00  0.0000 0.00     0    0
```


---

## Local independence 


.center[What]

The probability of the observing certain responses to a set of items is equal to the product of the probabilities associated with each response to each item: 

`$$P(x_{p1}, x_{p2}, \ldots, x_{pi}) = P(x_{p1})P(x_{p2}) \ldots P(x_{pi})$$`

The correlation between the observed responses "disappears" once the effect of the latent variable has been taken into account


.center[If violated]

There is something else other than the latent variable, issues for the validity and reliability of the measure 


---

## Local indepedence - How


It is based on the correlations between the residuals of the IRT model `\(\rightarrow\)` the distance between the observed data and the data expected according to the model 


Under the assumption of local independence, the residuals are expected not to be correlated 

The usual statistics for interpreting the correlation between the residuals is the `\(Q3\)` statistics (Yen, 1984) 

This statistics is computed for every pair of items

`\(Q3 &gt; .20\)` suggests an high correlation between the residuals of two items, indicating local dependence `\(\rightarrow\)` one of the item should be deleted 


---

class: section, center, middle

# Model estimation

---



## Model estimation in R

Multiple-choice items, coded as 0 (incorrect response) and 1 (correct response): 

.scrollable[

```r
m1pl = tam.mml(data, verbose = F)

m2pl = tam.mml.2pl(data, irtmodel = "2PL", verbose = F)

m3pl = tam.mml.3pl(data, est.guess = colnames(data),
                     verbose = F)
```

]

---
## Model comparison 


```r
IRT.compareModels(m1pl, m2pl, m3pl)
```

```{.scroll-100}
## $IC
##   Model   loglike Deviance Npars Nobs      AIC      BIC     AIC3     AICc
## 1  m1pl -2706.625 5413.250     6 1000 5425.250 5454.697 5431.250 5425.335
## 2  m2pl -2654.262 5308.525    10 1000 5328.525 5377.602 5338.525 5328.747
## 3  m3pl -2654.822 5309.644    16 1000 5341.644 5420.168 5357.644 5342.197
##       CAIC       GHP
## 1 5460.697 0.5425250
## 2 5387.602 0.5328525
## 3 5436.168 0.5341644
## 
## $LRtest
##   Model1 Model2       Chi2 df p
## 1   m1pl   m2pl 104.725382  4 0
## 2   m1pl   m3pl 103.606273 10 0
## 3   m2pl   m3pl  -1.119109  6 1
## 
## attr(,"class")
## [1] "IRT.compareModels"
```


---

## 2PL - Model fit 




```r
f.m2pl = tam.modelfit(m2pl, progress = F)
f.m2pl$statlist
```

```{.scroll-100}
##   X100.MADCOV        SRMR      SRMSR     MADaQ3 pmaxX2
## 1   0.2043301 0.009127058 0.01265885 0.07103058      1
```

```r
f.m2pl$modelfit.test
```

```{.scroll-100}
##       maxX2 Npairs p.holm
## 1 0.8595675     10      1
```



---






---

## 2PL - Fit 


```r
fit_m2pl = tam.modelfit(m2pl, progress = F)

fit_m2pl$statlist
```

```{.scroll-100}
##   X100.MADCOV        SRMR      SRMSR     MADaQ3 pmaxX2
## 1   0.2043301 0.009127058 0.01265885 0.07103058      1
```

```r
fit_m2pl$modelfit.test
```

```{.scroll-100}
##       maxX2 Npairs p.holm
## 1 0.8595675     10      1
```


---

## Local dependence


```r
fit_m2pl$Q3_summary
```

```{.scroll-100}
##   type             M         SD        min         max      SGDDM     wSGDDM
## 1   Q3 -1.686040e-01 0.09870174 -0.4230942 -0.06357212 0.16860403 0.16860403
## 2  aQ3 -3.552714e-18 0.09870174 -0.2544902  0.10503191 0.07103058 0.07103058
```



---


## 2PL - Item parameters


&lt;img src="stimareImodelli_files/figure-html/unnamed-chunk-22-1.png" width="60%" style="display: block; margin: auto;" /&gt;



---
class: section, center, middle

#  Information Functions
 

---

## 2PL - IIF 


&lt;img src="stimareImodelli_files/figure-html/unnamed-chunk-23-1.png" width="60%" style="display: block; margin: auto;" /&gt;




---


## 2PL - SE


```r
ggplot(info2pl$test_info, 
       aes(x = theta, y = info)) + geom_line(lwd = 2) + theme_bw()
```

&lt;img src="stimareImodelli_files/figure-html/unnamed-chunk-24-1.png" width="40%" style="display: block; margin: auto;" /&gt;


## SE 


```r
ggplot(info2pl$test_info, 
       aes(x = theta, y = se, col = "red")) + geom_line(lwd = 2) + theme_bw() + theme(legend.position = "none")
```

&lt;img src="stimareImodelli_files/figure-html/unnamed-chunk-25-1.png" width="40%" style="display: block; margin: auto;" /&gt;




---

## SE per il 2PL 

.scrollable[


]




---

---
class: section, center, middle

#  Esercitazione
 

---

## Esercitazione stima

Scaricare il dataset `dataES_stima.csv` dalla cartella [Dati](https://drive.google.com/drive/folders/1PXDG7HhjRDMdFEQjk5WQQWdiorDpSgtw?usp=sharing)

Look at the data!

Fittare i modelli IRT

Scegliere il modello più appropriato 

Valutarne la fit (sia del modello sia degli item)

Valutare le assunzioni

IIC, IIF, TIF



---

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"countIncrementalSlides": false,
"highlightLines": true,
"highlightLanguage": "r"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
